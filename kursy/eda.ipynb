{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random_state = 67\n",
    "\n",
    "bank_marketing = fetch_ucirepo(id=222)\n",
    "X = bank_marketing.data.features\n",
    "y = bank_marketing.data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dcfb12",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6493094",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y))\n",
    "print(y.shape)\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_series = y.iloc[:,0]\n",
    "print(y_series.value_counts())\n",
    "print(y_series.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(data = y, x = y_series, palette='hls')\n",
    "plt.title(\"Distribution of y\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9461c7",
   "metadata": {},
   "source": [
    "Target jest mocno niezbalansowany, przez co podczas liczenia metryk nie będziemy opierać się na accuracy(baseline ~0.88 dla 'no'), będziemy raczej chcieli patrzeć na recall/f1 dla 'yes'. Threshold 0.5 też nie będzie dobry przy takim rozkładzie y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63da92cb",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f4b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eda = X.copy()\n",
    "print(X_eda.head())\n",
    "print(X_eda.dtypes)\n",
    "print(X_eda.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0143f4",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_eda.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d47e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = X_eda.isna().sum().to_frame()\n",
    "missing_cols = missing_cols[missing_cols.loc[:,0] > 0].index\n",
    "for col in missing_cols:\n",
    "    print('unknown' in X_eda.loc[:,col].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e2523",
   "metadata": {},
   "source": [
    "Kolumny gdzie są brakujące dane maja dtype = object oraz nie mają w sobie defaultowo 'unknown', także zamienimy brakujące wartośći na 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eda.loc[:,missing_cols] = X_eda.loc[:,missing_cols].fillna('unknown')\n",
    "print(X_eda.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1a914",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29144f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_eda.select_dtypes('number').columns.tolist()\n",
    "cat_cols = X_eda.select_dtypes('object').columns.tolist()\n",
    "print(X_eda.loc[:,num_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceca2dc",
   "metadata": {},
   "source": [
    "Duration mówi nam o czasie rozmowy, a znamy ją dopiero po zakończeniu jej, dlatego usuwamy ją."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e590399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_y = X_eda.copy()\n",
    "df_with_y['y'] = y_series\n",
    "if 'duration' in df_with_y.columns:\n",
    "    df_with_y.drop(columns=['duration'], inplace=True)\n",
    "\n",
    "num_cols_without_duration = df_with_y.select_dtypes('number').columns.tolist()\n",
    "\n",
    "for col in num_cols_without_duration:\n",
    "    sns.violinplot(data = df_with_y, x=\"y\", y=col, cut = 0, inner='quartile')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eba78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdays = df_with_y[df_with_y['pdays'] != -1].copy()\n",
    "sns.violinplot(data=df_pdays, x='y', y='pdays', cut=0, inner='quartile')\n",
    "plt.title('Pdays without -1')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bafbcd",
   "metadata": {},
   "source": [
    "### Corelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177134f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "y_bin = (y_series == \"yes\").astype('int')\n",
    "\n",
    "mi_num = mutual_info_classif(X_eda.loc[:,num_cols_without_duration], y=y_bin, random_state=random_state)\n",
    "mi_num = pd.Series(mi_num, index=num_cols_without_duration).sort_values(ascending=False)\n",
    "print(mi_num.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def cramer_v(x,y):\n",
    "    ct = pd.crosstab(x,y)\n",
    "    chi2, p, dof, freq = chi2_contingency(ct)\n",
    "    n = ct.to_numpy().sum()\n",
    "    r, k = ct.shape\n",
    "    v = np.sqrt((chi2/n)/(min(r-1,k-1)))\n",
    "    return v, chi2, p, dof, r, k\n",
    "\n",
    "rows = []\n",
    "for col in cat_cols:\n",
    "    v, chi2, p, dof, r, k = cramer_v(X_eda.loc[:,col], y_bin)\n",
    "    rows.append({\n",
    "        \"feature\": col,\n",
    "        \"cramers_v\": v,\n",
    "        \"chi2\": chi2,\n",
    "        \"p-value\": p,\n",
    "        \"n_categories\": r\n",
    "    })\n",
    "\n",
    "cramers_rank = pd.DataFrame(rows).sort_values(by=\"cramers_v\", ascending=False)\n",
    "print(cramers_rank.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff19f1",
   "metadata": {},
   "source": [
    "## EDA summary\n",
    "\n",
    "- Niezbalansowany target (~12% yes)\n",
    "- Duration znane dopiero po rozmowie\n",
    "- Braki danych w kolumnach kategorycznych\n",
    "- Specjalna flaga -1 dla pdays jeżeli ktoś nie był kontaktowany\n",
    "- Kolumny numeryczne mają duże zakresy, dla modeli liniowych można użyć scalerów\n",
    "- Z kategorycznych największy związek z targetem ma poutcome, month, contact, housing, job\n",
    "- Katerogyczne wymagają OneHotEncdoing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dc5f77",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prep = X.copy()\n",
    "\n",
    "if 'duration' in X_prep.columns:\n",
    "    X_prep.drop(columns=['duration'], inplace=True)\n",
    "\n",
    "if 'pdays' in X_prep.columns:\n",
    "    X_prep['prev_contacted'] = (X_prep['pdays'] != -1).astype('int')\n",
    "    X_prep['pdays_clean'] = X_prep['pdays'].where(X_prep['pdays'] != -1, np.nan)\n",
    "    X_prep.drop(columns=['pdays'], inplace=True)\n",
    "\n",
    "print(X_prep.dtypes)\n",
    "print(X_prep.shape)\n",
    "print(X_prep.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d39f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_prep,\n",
    "    y_bin,\n",
    "    test_size=0.2,\n",
    "    stratify=y_bin,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    stratify=y_train,\n",
    "    random_state= random_state,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "num_cols = X_tr.select_dtypes('number').columns.tolist()\n",
    "cat_cols = X_tr.select_dtypes('object').columns.tolist()\n",
    "\n",
    "num_skew_pos_cols = ['campaign', 'previous']\n",
    "num_skew_signed_cols = ['balance']\n",
    "num_rest_cols = [c for c in num_cols if c not in num_skew_pos_cols + num_skew_signed_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcab677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def log1p(X):\n",
    "    X = X.copy()\n",
    "    X[:,:] = np.log1p(X)\n",
    "    return X\n",
    "\n",
    "def signed_log1p(X):\n",
    "    X = X.copy()\n",
    "    X[:, :] = np.sign(X) * np.log1p(np.abs(X))\n",
    "    return X\n",
    "\n",
    "num_skew_pos_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"log\", FunctionTransformer(log1p)),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "num_skew_signed_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"slog\", FunctionTransformer(signed_log1p)),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "num_rest_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', min_frequency=20))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    ('num_rest', num_rest_pipe, num_rest_cols),\n",
    "    ('cat', cat_pipe, cat_cols),\n",
    "    (\"skew_pos\", num_skew_pos_pipe, num_skew_pos_cols),\n",
    "    (\"skew_signed\", num_skew_signed_pipe, num_skew_signed_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94879529",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "pipe_lr = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', LogisticRegression(max_iter = 5000))\n",
    "])\n",
    "\n",
    "C_grid = np.logspace(-4,1,12)\n",
    "\n",
    "params_lr = [\n",
    "    {\"model__solver\": [\"lbfgs\"], \"model__C\": C_grid, \"model__l1_ratio\": [0], \"model__class_weight\": [None, \"balanced\"]},\n",
    "    {\"model__solver\": [\"liblinear\"], \"model__C\": C_grid, \"model__l1_ratio\": [0,1], \"model__class_weight\": [None, \"balanced\"]}\n",
    "]\n",
    "\n",
    "cv = StratifiedKFold(n_splits =5, shuffle=True, random_state=random_state)\n",
    "\n",
    "gs_lr = GridSearchCV(\n",
    "    pipe_lr,\n",
    "    param_grid=params_lr,\n",
    "    scoring='average_precision',\n",
    "    cv= cv,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "gs_lr.fit(X_tr, y_tr)\n",
    "\n",
    "best_lr = gs_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82178d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report, average_precision_score\n",
    "\n",
    "proba_lr = best_lr.predict_proba(X_val)[:,1]\n",
    "thr = np.linspace(0.05, 0.95, 200)\n",
    "\n",
    "best_thr_lr, best_f1_lr = None, -1\n",
    "for t in thr:\n",
    "    pred_lr = (proba_lr >= t).astype(int)\n",
    "    f1 = f1_score(y_val, pred_lr)\n",
    "    if f1 > best_f1_lr:\n",
    "        best_thr_lr, best_f1_lr = t, f1\n",
    "\n",
    "pred_val_lr = (proba_lr >= best_thr_lr).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd289942",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Threshold = {best_thr_lr}\")\n",
    "print(f\"Precision = {precision_score(y_val, pred_val_lr)}\")\n",
    "print(f\"Recall = {recall_score(y_val, pred_val_lr)}\")\n",
    "print(f\"F1 = {best_f1_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr = gs_lr.best_estimator_\n",
    "final_lr.fit(X_train, y_train)\n",
    "final_proba_lr = final_lr.predict_proba(X_test)[:,1]\n",
    "final_pred_lr = (final_proba_lr >= best_thr_lr).astype(int)\n",
    "\n",
    "print(\"---- Final model -----\")\n",
    "print(f\"AP = {average_precision_score(y_test, final_proba_lr)}\")\n",
    "print(f\"F1 = {f1_score(y_test, final_pred_lr)}\")\n",
    "print(f\"Recall = {recall_score(y_test, final_pred_lr)}\")\n",
    "print(f\"Precision = {precision_score(y_test, final_pred_lr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a416006",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----- Classification raport -----\")\n",
    "print(classification_report(y_test, final_pred_lr, target_names=[\"no\", \"yes\"], zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee33088d",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_prep = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', min_frequency=20), cat_cols),\n",
    "    ('num', num_rest_pipe, num_cols)\n",
    "])\n",
    "\n",
    "pipe_rf = Pipeline(steps=[\n",
    "    ('preprocess', rf_prep),\n",
    "    ('rf', RandomForestClassifier(random_state=random_state, n_jobs=-1, class_weight=\"balanced_subsample\"))\n",
    "])\n",
    "\n",
    "rf_grid_params = {\n",
    "    \"rf__n_estimators\": [400,425,450],\n",
    "    \"rf__min_samples_leaf\": [5,10,15], \n",
    "    \"rf__max_depth\": [36,40],\n",
    "    \"rf__max_features\": [\"sqrt\"]\n",
    "}\n",
    "\n",
    "gs_rf = GridSearchCV(\n",
    "    pipe_rf,\n",
    "    param_grid= rf_grid_params,\n",
    "    scoring='average_precision',\n",
    "    cv=cv,\n",
    "    n_jobs = -1,\n",
    ")\n",
    "\n",
    "gs_rf.fit(X_tr, y_tr)\n",
    "best_rf = gs_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5ac3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_rf = best_rf.predict_proba(X_val)[:,1]\n",
    "\n",
    "best_thr_rf, best_f1_rf = None, -1\n",
    "for t in thr:\n",
    "    pred = (proba_rf >= t).astype(int)\n",
    "    f1 = f1_score(y_val, pred)\n",
    "    if f1 > best_f1_rf:\n",
    "        best_thr_rf, best_f1_rf = t, f1\n",
    "\n",
    "pred_rf = (proba_rf >= best_thr_rf).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best THR = {best_thr_rf}\")\n",
    "print(f\"Recall = {recall_score(y_val, pred_rf)}\")\n",
    "print(f\"F1 = {best_f1_rf}\")\n",
    "print(f\"Prec = {precision_score(y_val, pred_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea779a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rf = gs_rf.best_estimator_\n",
    "final_rf.fit(X_train, y_train)\n",
    "final_proba_rf = final_rf.predict_proba(X_test)[:,1]\n",
    "final_pred_rf = (final_proba_rf >= best_thr_rf).astype(int)\n",
    "\n",
    "print(\"---- Final model -----\")\n",
    "print(f\"AP = {average_precision_score(y_test, final_proba_rf)}\")\n",
    "print(f\"F1 = {f1_score(y_test, final_pred_rf)}\")\n",
    "print(f\"Recall = {recall_score(y_test, final_pred_rf)}\")\n",
    "print(f\"Precision = {precision_score(y_test, final_pred_rf)}\")\n",
    "print(classification_report(y_test, final_pred_rf, target_names=[\"no\", \"yes\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40fdcbc",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_cols_svm_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "preprocess_svm = ColumnTransformer(transformers=[\n",
    "    ('num', num_cols_svm_pipe, num_cols),\n",
    "    ('cat', cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "pipe_svm = Pipeline(steps=[\n",
    "    ('preprocess', preprocess_svm),\n",
    "    ('svm', LinearSVC(max_iter = 15000, random_state=random_state))\n",
    "])\n",
    "\n",
    "C_grid_svm = np.logspace(-3,1,12)\n",
    "\n",
    "param_grid_svm = {\n",
    "    \"svm__C\": C_grid_svm,\n",
    "    \"svm__class_weight\": [None, \"balanced\"],\n",
    "    \"svm__loss\": [\"squared_hinge\"]\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV(\n",
    "    pipe_svm,\n",
    "    param_grid=param_grid_svm,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"average_precision\"\n",
    ")\n",
    "\n",
    "gs_svm.fit(X_tr, y_tr)\n",
    "\n",
    "best_svm = gs_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e178964",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = best_svm.decision_function(X_val)\n",
    "\n",
    "t_min, t_max = np.percentile(val_scores, 1), np.percentile(val_scores, 99)\n",
    "\n",
    "thr_svm = np.linspace(t_min, t_max, 200)\n",
    "\n",
    "best_thr_svm, best_f1_svm = None, -1\n",
    "for t in thr_svm:\n",
    "    pred = (val_scores >= t).astype(int)\n",
    "    f1 = f1_score(y_val, pred)\n",
    "    if f1 > best_f1_svm:\n",
    "        best_thr_svm, best_f1_svm = t, f1\n",
    "\n",
    "val_pred = (val_scores >= best_thr_svm).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_svm = gs_svm.best_estimator_\n",
    "final_svm.fit(X_train, y_train)\n",
    "final_proba_svm = final_svm.decision_function(X_test)\n",
    "final_pred_svm = (final_proba_svm >= best_thr_svm).astype(int)\n",
    "\n",
    "print(\"---- Final model -----\")\n",
    "print(f\"AP = {average_precision_score(y_test, final_proba_svm)}\")\n",
    "print(f\"F1 = {f1_score(y_test, final_pred_svm)}\")\n",
    "print(f\"Recall = {recall_score(y_test, final_pred_svm)}\")\n",
    "print(f\"Precision = {precision_score(y_test, final_pred_svm)}\")\n",
    "print(classification_report(y_test, final_pred_svm, target_names=[\"no\", \"yes\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1cda7a",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "pre = final_rf.named_steps['preprocess']\n",
    "rf = final_rf.named_steps['rf']\n",
    "\n",
    "feature_names = pre.get_feature_names_out()\n",
    "\n",
    "X_train_rf = pre.transform(X_train)\n",
    "X_test_rf = pre.transform(X_test)\n",
    "X_bg = pre.transform(X_train.sample(200, random_state=random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_test)\n",
    "y_pred = final_rf.predict(X_test)\n",
    "\n",
    "tp_idx = np.where((y_true == 1) & (y_pred == 1))[0][0]\n",
    "fn_idx = np.where((y_true == 1) & (y_pred == 0))[0][0]\n",
    "\n",
    "X_two = X_test_rf[[tp_idx, fn_idx]]\n",
    "\n",
    "explainer = shap.TreeExplainer(rf, data=X_bg)\n",
    "shap_values = explainer.shap_values(X_two, check_additivity=False)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "\n",
    "    sv_yes = shap_values[1]\n",
    "    base_yes = explainer.expected_value[1]\n",
    "else:\n",
    "    sv_yes = shap_values[:, :, 1]\n",
    "    base_yes = explainer.expected_value[1]\n",
    "\n",
    "def row_to_dense(X_row):\n",
    "    return X_row.toarray().ravel() if hasattr(X_row, \"toarray\") else np.array(X_row).ravel()\n",
    "\n",
    "x0 = row_to_dense(X_two[0])\n",
    "exp0 = shap.Explanation(values=sv_yes[0], base_values=base_yes, data=x0, feature_names=feature_names)\n",
    "shap.plots.waterfall(exp0, max_display=10)\n",
    "\n",
    "x1 = row_to_dense(X_two[1])\n",
    "exp1 = shap.Explanation(values=sv_yes[1], base_values=base_yes, data=x1, feature_names=feature_names)\n",
    "shap.plots.waterfall(exp1, max_display=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-kurs-wdrozeniowy-25 (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
